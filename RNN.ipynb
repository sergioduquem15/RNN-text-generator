{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt\n",
      "106496/99993 [===============================] - 0s 2us/step\n",
      "99993\n"
     ]
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file('shakespear.txt','https://cs.stanford.edu/people/karpathy/char-rnn/shakespear.txt')\n",
    "text = open(path,'rb').read().decode(encoding='utf-8')\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', \"'\", ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     '\\n':  0,\n",
      "     ' ' :  1,\n",
      "     '!' :  2,\n",
      "     \"'\" :  3,\n",
      "     ',' :  4,\n",
      "     '-' :  5,\n",
      "     '.' :  6,\n",
      "     ':' :  7,\n",
      "     ';' :  8,\n",
      "     '?' :  9,\n",
      "     'A' : 10,\n",
      "     'B' : 11,\n",
      "     'C' : 12,\n",
      "     'D' : 13,\n",
      "     'E' : 14,\n",
      "     'F' : 15,\n",
      "     'G' : 16,\n",
      "     'H' : 17,\n",
      "     'I' : 18,\n",
      "     'J' : 19,\n",
      "     'K' : 20,\n",
      "     'L' : 21,\n",
      "     'M' : 22,\n",
      "     'N' : 23,\n",
      "     'O' : 24,\n",
      "     'P' : 25,\n",
      "     'Q' : 26,\n",
      "     'R' : 27,\n",
      "     'S' : 28,\n",
      "     'T' : 29,\n",
      "     'U' : 30,\n",
      "     'V' : 31,\n",
      "     'W' : 32,\n",
      "     'X' : 33,\n",
      "     'Y' : 34,\n",
      "     'Z' : 35,\n",
      "     'a' : 36,\n",
      "     'b' : 37,\n",
      "     'c' : 38,\n",
      "     'd' : 39,\n",
      "     'e' : 40,\n",
      "     'f' : 41,\n",
      "     'g' : 42,\n",
      "     'h' : 43,\n",
      "     'i' : 44,\n",
      "     'j' : 45,\n",
      "     'k' : 46,\n",
      "     'l' : 47,\n",
      "     'm' : 48,\n",
      "     'n' : 49,\n",
      "     'o' : 50,\n",
      "     'p' : 51,\n",
      "     'q' : 52,\n",
      "     'r' : 53,\n",
      "     's' : 54,\n",
      "     't' : 55,\n",
      "     'u' : 56,\n",
      "     'v' : 57,\n",
      "     'w' : 58,\n",
      "     'x' : 59,\n",
      "     'y' : 60,\n",
      "     'z' : 61,\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "for char,_ in zip(char2idx,range(len(vocab))):\n",
    "    print('     {:4s}:{:3d},'.format(repr(char),char2idx[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"That, poor contempt, or claim'd thou slept so fait\"\n",
      "array([29, 43, 36, 55,  4,  1, 51, 50, 50, 53,  1, 38, 50, 49, 55, 40, 48,\n",
      "       51, 55,  4,  1, 50, 53,  1, 38, 47, 36, 44, 48,  3, 39,  1, 55, 43,\n",
      "       50, 56,  1, 54, 47, 40, 51, 55,  1, 54, 50,  1, 41, 36, 44, 55])\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "print(repr(text[:50]))\n",
    "print('{}'.format(repr(text_as_int[:50])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"That, poor contempt, or claim'd thou slept so faithful,\\nI may contrive our father; and, in their defe\"\n",
      "'ated queen,\\nHer flesh broke me and puttance of expedition house,\\nAnd in that same that ever I lament '\n",
      "'this stomach,\\nAnd he, nor Butly and my fury, knowing everything\\nGrew daily ever, his great strength a'\n",
      "\"nd thought\\nThe bright buds of mine own.\\n\\nBIONDELLO:\\nMarry, that it may not pray their patience.'\\n\\nKIN\"\n",
      "'G LEAR:\\nThe instant common maid, as we may less be\\na brave gentleman and joiner: he that finds us wit'\n",
      "\"h wax\\nAnd owe so full of presence and our fooder at our\\nstaves. It is remorsed the bridal's man his g\"\n",
      "'race\\nfor every business in my tongue, but I was thinking\\nthat he contends, he hath respected thee.\\n\\nB'\n",
      "\"IRON:\\nShe left thee on, I'll die to blessed and most reasonable\\nNature in this honour, and her bosom \"\n",
      "'is safe, some\\nothers from his speedy-birth, a bill and as\\nForestem with Richard in your heart\\nBe ques'\n",
      "\"tion'd on, nor that I was enough:\\nWhich of a partier forth the obsers d'punish'd the hate\\nTo my restr\"\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "seq_length = 100\n",
    "sequences = char_dataset.batch(seq_length+1,drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(10):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function split_input_target at 0x0000028C857F0310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function split_input_target at 0x0000028C857F0310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text,target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"That, poor contempt, or claim'd thou slept so faithful,\\nI may contrive our father; and, in their def\"\n",
      "Target data:  \"hat, poor contempt, or claim'd thou slept so faithful,\\nI may contrive our father; and, in their defe\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ',repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ',repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size,embedding_dim,rnn_units,batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,embedding_dim,\n",
    "                                  batch_input_shape=[batch_size,None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (64, None, 256)           15872     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 62)            63550     \n",
      "=================================================================\n",
      "Total params: 5,326,398\n",
      "Trainable params: 5,326,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (64, 100) # (batch_size, sequence_lenght)\n",
      "Target: (64, 100) # (batch_size, sequence_lenght)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input:\",input_example_batch.shape,\"# (batch_size, sequence_lenght)\")\n",
    "    print(\"Target:\",target_example_batch.shape,\"# (batch_size, sequence_lenght)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  (64, 100, 62) # (batch_size,sequence_lenght,vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(\"Prediction: \", example_batch_predictions.shape, \"# (batch_size,sequence_lenght,vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40 52  3 14 49 34 16 51 37  6 26 35  5 51 40 51  2 56 52 43 47 13 18 11\n",
      " 26 13 12  2 42 59 45 33  1 58  7 43 12 48 15 55 41 61 29  5 56 11 57 11\n",
      " 30 51  7  2 26 51 23 54 28 41 14 32 45 58 27 59 38  7  1 18 32  2 13 11\n",
      " 41 58 40  5  1 47 11 54 28 57 55 23 23 36 56 42 41  2 14 48 49  7 15 49\n",
      " 52  8 53 16]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
    "sampled_indices_characters = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "print(sampled_indices_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels,logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 25s 2s/step - loss: 3.2125\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 3.0661\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 26s 2s/step - loss: 2.7132\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 2.4968\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 2.3822\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 2.3059\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 2.2450\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 2.1836\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 2.1297\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 2.0801\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 2.0313\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.9807\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.9335\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 31s 2s/step - loss: 1.8916\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.8469\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.8045\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.7620\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.7216\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.6817\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.6451\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.5999\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.5570\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.5129\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 1.4647\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.4150\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 30s 2s/step - loss: 1.3655\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 29s 2s/step - loss: 1.3169\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 1.2602\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 1.2024\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 1.1388\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 1.0728\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 1.0096\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.9448\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.8789\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.8090\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.7455\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.6857\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.6282\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.5740\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.5261\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.4872\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.4510\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.4191\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3925\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 28s 2s/step - loss: 0.3709\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3519\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3361\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3200\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.3066\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 27s 2s/step - loss: 0.2993\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size,embedding_dim,rnn_units,batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_string):\n",
    "    num_generate = 500\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 0.5\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "        predictions = predictions/temperature\n",
    "        predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id],0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "    return (start_string+\"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohold him staff.\n",
      "\n",
      "KING PHILIP:\n",
      "Ay, but you do not in the sight of Norfolk live such ground\n",
      "My tongue shall be brief in the dearcons a speed;\n",
      "And well well in the our own officers and preether,\n",
      "But never will that should be melted as you have in language.\n",
      "\n",
      "CORIOLANUS:\n",
      "Wherefore, Volscous?\n",
      "Hang you to any as my husband, and out and a part, so gentle this time.\n",
      "\n",
      "FALSTAFF:\n",
      "I will challenge this good creature, and some break together:\n",
      "But such a friends and presentle between; and thus army army'd to the \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,start_string=u\"Alcohol\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronath some mestly ted\n",
      "And the chy fair in kind;\n",
      "And despres did with a goodly ducats!\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Why, so something becomes my strength, how add\n",
      "their sword of thee!\n",
      "Duth the stryection and the moud of Corfess;\n",
      "Prother of your hands with sight with a greet bedory my streegnt of heaven and them that begg'd it\n",
      "\n",
      "ElvINA:\n",
      "Now, for my mouth, men walk in both the sea:\n",
      "On head not call thought to speak, with me.\n",
      "\n",
      "GUKE OF YORK:\n",
      "I'll praper a shormed, her couns?\n",
      "\n",
      "Fersenter:\n",
      "Ay, that it sooner saw me gon\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,start_string=u\"Neurona\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humanidad you here,\n",
      "Or the lest not live a frolt of this thought\n",
      "I'll slep it ander to the sun as his man:\n",
      "And did thou should ever I fair.\n",
      "\n",
      "DUCHESS:\n",
      "Nay, I'll ever throw his honour.\n",
      "\n",
      "OTHELLO:\n",
      "Good morrow, amen.\n",
      "\n",
      "CRESSIDA:\n",
      "To stop the callert peace, would not then he stands, and such a fould of deaven.\n",
      "\n",
      "CLEOPATRA:\n",
      "What is 'Tis more, Brutus? They are bloody the seas:\n",
      "Whiles we are ploody of her father and his same\n",
      "That gleats I death in many hearts to observe\n",
      "To take what they have here?\n",
      "\n",
      "PASSIUS:\n",
      "On my Lo\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,start_string=u\"humanidad \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "641f53da7ea006dcf7a70b9aed402687529bbfe00a8ed96de5047ff3d3525b80"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
